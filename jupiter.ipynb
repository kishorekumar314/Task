{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Set Up Environment\n",
    "#Start by installing necessary libraries, including PySpark and any visualization libraries like Matplotlib or Seaborn\n",
    "\n",
    "#2.Load Data\n",
    "#python\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Credit Card Transactions Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset (assuming it's a CSV or JSON format)\n",
    "df = spark.read.json(\"path/to/your/dataset.json\")  # or .csv if applicable\n",
    "\n",
    "#3.Data Exploration\n",
    "df.show()\n",
    "df.printSchema()\n",
    "\n",
    "#4.Data Cleaning and Transformation\n",
    "#Handling PII Data:Identify and discuss which columns contain PII (e.g., names, credit card numbers, etc.)\n",
    "#Data Quality Assurance:\n",
    "\n",
    "# Check for null values\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "# Example of dropping rows with null values\n",
    "df = df.na.drop()\n",
    "\n",
    "#JSON Flattening:Flatten any JSON data if applicable, using functions like explode() if you encounter nested structures\n",
    "\n",
    "# Flatten the JSON structure (if needed)\n",
    "# df = df.withColumn(\"new_column\", explode(df.json_column))\n",
    "\n",
    "#Timestamp Conversion:\n",
    "\n",
    "from pyspark.sql.functions import from_utc_timestamp, to_timestamp\n",
    "\n",
    "df = df.withColumn(\"trans_date_trans_time\", from_utc_timestamp(to_timestamp(\"trans_date_trans_time\"), \"UTC+8\"))\n",
    "# Repeat for other timestamp columns as necessary.\n",
    "\n",
    "\n",
    "#Name Derivation:\n",
    "\n",
    "#Derive first and last names from a person_name column, handling any dirty\n",
    "\n",
    "from pyspark.sql.functions import split, trim\n",
    "\n",
    "df = df.withColumn(\"first\", trim(split(df.person_name, \",\").getItem(0)))\n",
    "df = df.withColumn(\"last\", trim(split(df.person_name, \",\").getItem(1)))\n",
    "\n",
    "\n",
    "#5.Visualizations and Analysis\n",
    "\n",
    "Import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to Pandas for visualization if necessary\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Example visualization: Total transactions by category\n",
    "transaction_counts = pdf['category'].value_counts()\n",
    "transaction_counts.plot(kind='bar')\n",
    "plt.title('Transaction Counts by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "### Data Cleaning Process\n",
    "#The dataset contained various null values and inconsistencies, particularly within the `person_name` field. We separated this into first and last names using a split approach, ensuring values are trimmed to remove excess whitespace.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
